{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### In the below code, we see the direct strategy applied using the hybrid CNN-LSTM model with attention. NASDAQ with symbol ^IXIC data is downloaded. In the first model, the data is first preporcessed using the direct strategy, sliding window method. The first difference is taken to make the data staionary, this helps the models forecast accuracy. The data is then split into test and train sets and fed into the neural network. The actual and predicted values are compared and the The root mean square error is 47 as seen below."
      ],
      "metadata": {
        "id": "uHqjC5SW18J4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Direct Strategy"
      ],
      "metadata": {
        "id": "YuxiSVPPXaPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, BatchNormalization, Activation, Flatten, Reshape, Attention\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "\n",
        "# Get  stock data\n",
        "data = yf.download('^IXIC', start='2005-01-01', end='2017-12-31').diff().dropna()\n",
        "\n",
        "# Preprocess the data for LSTM\n",
        "def preprocess_data(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps):\n",
        "        X.append(data[i:i+n_steps])\n",
        "        y.append(data[i+n_steps])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "n_steps = 10  # number of time steps to consider for each sample\n",
        "train_size = int(len(data)*0.8)\n",
        "test_size = len(data) - train_size\n",
        "\n",
        "X_train, y_train = preprocess_data(data['Close'].values[:train_size], n_steps)\n",
        "X_test, y_test = preprocess_data(data['Close'].values[train_size:], n_steps)\n",
        "\n",
        "# Define the Conv-LSTM-Att model with the direct strategy\n",
        "inputs = tf.keras.layers.Input(shape=(n_steps, 1))\n",
        "conv1d = Conv1D(32, kernel_size=3, padding='same', strides=1)(inputs)\n",
        "lstm = LSTM(100, return_sequences=True)(conv1d)\n",
        "query, value = tf.split(lstm, 2, axis=2)\n",
        "attention = Attention(50)([query, value])\n",
        "batch_norm1 = BatchNormalization()(attention)\n",
        "dropout1 = Dropout(0.5)(batch_norm1)\n",
        "dense1 = Dense(64)(dropout1)\n",
        "batch_norm2 = BatchNormalization()(dense1)\n",
        "dropout2 = Dropout(0.2)(batch_norm2)\n",
        "output = Dense(1, activation='linear')(dropout2)\n",
        "model_direct = Model(inputs=inputs, outputs=output)\n",
        "model_direct.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "model_direct.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LXZhIgqmlfH",
        "outputId": "b5a21c96-b956-4993-c51e-7ab95317ef6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "163/163 [==============================] - 10s 17ms/step - loss: 1051.8833 - val_loss: 2228.1619\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 1051.1376 - val_loss: 2227.1780\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 2s 15ms/step - loss: 1050.8947 - val_loss: 2226.8677\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 1050.7260 - val_loss: 2226.3572\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 1050.5156 - val_loss: 2225.9155\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - 3s 17ms/step - loss: 1050.5148 - val_loss: 2225.6233\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 1050.4896 - val_loss: 2225.6091\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 1050.3994 - val_loss: 2225.3047\n",
            "Epoch 9/10\n",
            "163/163 [==============================] - 2s 15ms/step - loss: 1050.3508 - val_loss: 2224.9094\n",
            "Epoch 10/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 1050.2892 - val_loss: 2225.0813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb8820284c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "rmse = model_direct.evaluate(X_test, y_test)\n",
        "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(rmse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8jAE67lrDqo",
        "outputId": "b6d5b277-8398-4065-87af-5db279863bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 17ms/step - loss: 2225.0569\n",
            "Root Mean Squared Error (RMSE): 47.170508633738784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the below code, the data is not differenced and remains non stationary when it is fed into the model. This causes a drastic decrease in accuracy, increasing the root mean square error by over 5000."
      ],
      "metadata": {
        "id": "-6kfiRQi3KX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Direct Strategy Not diffferenced"
      ],
      "metadata": {
        "id": "KdJUXLLm1wog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, BatchNormalization, Activation, Flatten, Reshape, Attention\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Get  stock data\n",
        "data = yf.download('^IXIC', start='2005-01-01', end='2017-12-31')\n",
        "\n",
        "# Preprocess the data for LSTM\n",
        "def preprocess_data(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps):\n",
        "        X.append(data[i:i+n_steps])\n",
        "        y.append(data[i+n_steps])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "n_steps = 10  # number of time steps to consider for each sample\n",
        "train_size = int(len(data)*0.8)\n",
        "test_size = len(data) - train_size\n",
        "\n",
        "X_train, y_train = preprocess_data(data['Close'].values[:train_size], n_steps)\n",
        "X_test, y_test = preprocess_data(data['Close'].values[train_size:], n_steps)\n",
        "\n",
        "# Define the Conv-LSTM-Att model with the direct strategy\n",
        "inputs = tf.keras.layers.Input(shape=(n_steps, 1))\n",
        "conv1d = Conv1D(32, kernel_size=3, padding='same', strides=1)(inputs)\n",
        "lstm = LSTM(100, return_sequences=True)(conv1d)\n",
        "\n",
        "query, value = tf.split(lstm, 2, axis=2)\n",
        "attention = Attention(50)([query, value])\n",
        "\n",
        "batch_norm1 = BatchNormalization()(attention)\n",
        "dropout1 = Dropout(0.5)(batch_norm1)\n",
        "dense1 = Dense(64)(dropout1)\n",
        "batch_norm2 = BatchNormalization()(dense1)\n",
        "dropout2 = Dropout(0.2)(batch_norm2)\n",
        "output = Dense(1, activation='linear')(dropout2)\n",
        "\n",
        "model_direct = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model_direct.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "model_direct.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "# Evaluate the model on the test data\n",
        "rmse = model_direct.evaluate(X_test, y_test)\n",
        "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNYb-JH5u1h-",
        "outputId": "e137e6d2-fb15-4663-a941-756e9a62c5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "Epoch 1/10\n",
            "163/163 [==============================] - 8s 20ms/step - loss: 8408750.0000 - val_loss: 30355392.0000\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 8363910.0000 - val_loss: 30214440.0000\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 8270416.5000 - val_loss: 29976274.0000\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 8130110.5000 - val_loss: 29629464.0000\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 3s 17ms/step - loss: 7948677.5000 - val_loss: 29230304.0000\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - 3s 19ms/step - loss: 7730552.5000 - val_loss: 28773790.0000\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 7480912.0000 - val_loss: 28241686.0000\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 7204506.5000 - val_loss: 27647180.0000\n",
            "Epoch 9/10\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 6906018.5000 - val_loss: 27007026.0000\n",
            "Epoch 10/10\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 6588718.0000 - val_loss: 26316476.0000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 26316478.0000\n",
            "Root Mean Squared Error (RMSE): 5129.958869230824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Qz5VAaupA7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}